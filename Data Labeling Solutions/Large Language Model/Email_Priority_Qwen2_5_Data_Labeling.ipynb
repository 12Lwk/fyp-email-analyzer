{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsj_6Z09xuVS"
      },
      "source": [
        "## Qwen2.5 Email Prioritization - Data Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ne9Lt4DzODr",
        "outputId": "873af9d4-487d-4270-cf53-7a8fc39b6bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm pandas requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avU0ab3uwBCM",
        "outputId": "d7bdbd41-1dc6-453b-8e53-752006d3aa2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpbNwhhJxI_l",
        "outputId": "ac3cde9f-cb4a-4f80-cae7-5331bb9c6d36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025/03/28 09:16:52 routes.go:1230: INFO server config env=\"map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:2048 OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/root/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]\"\n",
            "time=2025-03-28T09:16:52.786Z level=INFO source=images.go:432 msg=\"total blobs: 0\"\n",
            "time=2025-03-28T09:16:52.786Z level=INFO source=images.go:439 msg=\"total unused blobs removed: 0\"\n",
            "time=2025-03-28T09:16:52.787Z level=INFO source=routes.go:1297 msg=\"Listening on 127.0.0.1:11434 (version 0.6.2)\"\n",
            "time=2025-03-28T09:16:52.787Z level=INFO source=gpu.go:217 msg=\"looking for compatible GPUs\"\n",
            "time=2025-03-28T09:16:52.948Z level=INFO source=types.go:130 msg=\"inference compute\" id=GPU-c6130e6c-59db-003f-678e-8f0e19194cf1 library=cuda variant=v12 compute=8.0 driver=12.4 name=\"NVIDIA A100-SXM4-40GB\" total=\"39.6 GiB\" available=\"39.1 GiB\"\n"
          ]
        }
      ],
      "source": [
        "!ollama serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qSDuevaxLPn"
      },
      "outputs": [],
      "source": [
        "!ollama pull qwen2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RvYcbWixqND",
        "outputId": "42c2f251-0e71-4d94-dc9a-ed00871b2f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?25l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[K\u001b[?25h\u001b[?2026l\u001b[2K\u001b[1G\u001b[?25h\u001b[?2004h>>> \u001b[38;5;245mSend a message (/? for help)\u001b[28D\u001b[0m^C\n"
          ]
        }
      ],
      "source": [
        "!ollama run qwen2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAIAHPyoA1aO",
        "outputId": "4e01ae9d-a65b-43f6-f21f-99a6902d9785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "🚀 Processing Emails: 100%|██████████| 20000/20000 [3:11:38<00:00,  1.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Email_Priority\n",
            "Medium    19802\n",
            "Low         131\n",
            "High         67\n",
            "Name: count, dtype: int64\n",
            "✅ Processed 20000 emails.\n",
            "✅ Processed file saved at: /content/drive/MyDrive/FYPDataset/email_batch_2_priority_qwen2.5.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Modify the file paths to match Google Drive locations\n",
        "file_path = \"/content/drive/MyDrive/FYPDataset/email_batch_2.csv\"  # Update this with your input file path on Google Drive\n",
        "email_data = pd.read_csv(file_path)\n",
        "\n",
        "email_data.head(10)\n",
        "\n",
        "# Check if necessary columns exist in the dataset\n",
        "if \"Subject_LLM\" not in email_data.columns or \"Message_LLM\" not in email_data.columns:\n",
        "    raise ValueError(\"🚨 ERROR: 'Subject_LLM' or 'Message_LLM' column not found in the dataset. Check the CSV file.\")\n",
        "\n",
        "# Define work-related keywords and urgent indicators\n",
        "work_keywords = {\n",
        "    'high_priority': [\n",
        "        'urgent', 'asap', 'deadline', 'important', 'critical', 'emergency',\n",
        "        'immediate attention', 'priority', 'action required', 'due today',\n",
        "        'overdue', 'urgent action', 'immediate response needed', 'time sensitive',\n",
        "        'urgent meeting', 'board meeting', 'regulatory', 'compliance deadline',\n",
        "        'immediate action', 'pressing', 'crucial', 'vital'\n",
        "    ],\n",
        "    'business_terms': [\n",
        "        'meeting', 'project', 'client', 'report', 'presentation', 'budget',\n",
        "        'deadline', 'deliverable', 'stakeholder', 'contract', 'proposal',\n",
        "        'review', 'approval', 'compliance', 'strategy', 'trading', 'energy',\n",
        "        'power', 'gas', 'deal', 'transaction', 'market', 'regulatory', 'filing',\n",
        "        'audit', 'financial', 'board', 'executive', 'partnership', 'agreement',\n",
        "        'merger', 'revenue', 'profit', 'loss', 'investment', 'stock', 'shares'\n",
        "    ]\n",
        "}\n",
        "\n",
        "def label_email_priority_llama3_3(subject, message, progress_bar):\n",
        "    \"\"\"Calls Qwen2.5 API and assigns priority to the email based on subject, message tone, and understanding.\"\"\"\n",
        "    prompt = f\"\"\"You are analyzing work-related emails to assign a priority level based on the subject, message content, tone, urgency, and business relevance.\n",
        "    Your task is to evaluate the email's level of urgency and importance using the following factors:\n",
        "\n",
        "    - **Subject Line**: Does it indicate a time-sensitive matter or an important business issue (e.g., meeting, deadline, urgent request)?\n",
        "    - **Message Content**: Does the message contain critical work-related information, such as a request for immediate action, a deadline, an important meeting, or a regulatory issue?\n",
        "    - **Tone**: Is the tone demanding or expressing urgency (e.g., using terms like 'ASAP', 'immediate attention', 'deadline', or 'urgent action')?\n",
        "    - **Business Relevance**: Does the email pertain to business operations, projects, meetings, client deadlines, compliance, or other critical work activities?\n",
        "\n",
        "    **Priority Levels (Choose exactly one based on your analysis):**\n",
        "    - **High**: The email requires immediate attention, involves urgent or critical business issues, or has a time-sensitive deadline.\n",
        "    - **Medium**: The email contains important information, but it is not immediately time-sensitive. It should be addressed soon but not immediately.\n",
        "    - **Low**: The email is non-urgent, contains general information, or can be dealt with later.\n",
        "\n",
        "    **Keywords to consider for urgency and importance**:\n",
        "    - Urgent terms: 'urgent', 'asap', 'deadline', 'important', 'critical', 'emergency', 'immediate attention', 'priority', 'action required', 'due today', 'overdue', 'urgent action'.\n",
        "    - Business terms: 'meeting', 'project', 'client', 'report', 'presentation', 'budget', 'contract', 'proposal', 'stakeholder', 'regulatory', 'audit', 'financial', 'transaction', 'market', 'compliance'.\n",
        "\n",
        "    **Subject**:\n",
        "    \"{subject}\"\n",
        "\n",
        "    **Message Content**:\n",
        "    \"{message}\"\n",
        "\n",
        "    **Priority (return only one from the list above):**\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"http://localhost:11434/api/generate\",\n",
        "            json={\n",
        "                'model': 'qwen2.5',\n",
        "                'prompt': prompt,\n",
        "                'stream': False,\n",
        "                'temperature': 0.1,\n",
        "                'max_tokens': 10\n",
        "            },\n",
        "            timeout=30\n",
        "        ).json()\n",
        "\n",
        "        predicted_priority = response.get('response', 'Error').strip()\n",
        "\n",
        "        valid_priorities = [\"High\", \"Medium\", \"Low\"]\n",
        "        if predicted_priority not in valid_priorities:\n",
        "            predicted_priority = \"Medium\"\n",
        "\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        return predicted_priority\n",
        "\n",
        "    except requests.exceptions.RequestException:\n",
        "        progress_bar.update(1)\n",
        "        return \"Error\"\n",
        "\n",
        "def process_batch_priority(batch, progress_bar):\n",
        "    return batch.apply(lambda row: label_email_priority_llama3_3(row['Subject_LLM'], row['Message_LLM'], progress_bar), axis=1)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "NUM_WORKERS = 8\n",
        "\n",
        "# Processing emails in batches with a progress bar\n",
        "with tqdm(total=len(email_data), desc=\"🚀 Processing Emails\") as progress_bar:\n",
        "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
        "        results = list(executor.map(\n",
        "            lambda batch: process_batch_priority(batch, progress_bar),\n",
        "            [email_data.iloc[i:i + BATCH_SIZE] for i in range(0, len(email_data), BATCH_SIZE)]\n",
        "        ))\n",
        "\n",
        "email_data[\"Email_Priority\"] = [priority for batch in results for priority in batch]\n",
        "\n",
        "output_file = \"/content/drive/MyDrive/FYPDataset/email_batch_2_priority_qwen2.5.csv\"\n",
        "email_data.to_csv(output_file, index=False)\n",
        "\n",
        "print(email_data[\"Email_Priority\"].value_counts())\n",
        "\n",
        "print(f\"✅ Processed {len(email_data)} emails.\")\n",
        "print(f\"✅ Processed file saved at: {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
